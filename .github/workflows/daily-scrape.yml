name: Scrape IVU and Publish ICS

on:
  schedule:
    - cron: '0 5 * * *'   # cada día 05:00 UTC
  workflow_dispatch:

permissions:
  contents: read          # para checkout
  pages: write            # <--- necesario para desplegar Pages
  id-token: write         # <--- necesario para deploy-pages

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4 icalendar pytz
      - name: Install Playwright browsers & OS deps
        run: |
          playwright install chromium
          playwright install-deps

      - name: Run scraper
        env:
          IVU_USER: ${{ secrets.IVU_USER }}
          IVU_PASS: ${{ secrets.IVU_PASS }}
        run: |
          mkdir -p public/calendars
          python scrape_and_publish.py > output.txt || (cat output.txt && exit 1)
          echo "----- Generated files -----"
          ls -R public || true

      - name: Upload debug artifacts (if any)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: debug-artifacts
          path: |
            debug/**
            output.txt

      # ===== Deploy con el método oficial Pages =====
      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
